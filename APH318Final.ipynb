{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72ef386-2fb1-420c-bee4-06ff57da5bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    "    StratifiedKFold,\n",
    "    cross_val_score\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "# Advanced models\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Explainability\n",
    "import shap\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# ==========================================\n",
    "# 1. DATA LOADING\n",
    "# ==========================================\n",
    "print(\">>> STEP 1: Loading Data...\")\n",
    "\n",
    "file_path = r\"C:\\Users\\admin\\Desktop\\diabetic_data.csv\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"Error: '{file_path}' not found.\")\n",
    "\n",
    "# Load CSV, treat '?' as missing values\n",
    "df = pd.read_csv(file_path, na_values=\"?\", low_memory=False)\n",
    "\n",
    "# Basic cleaning: remove duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print(f\"Data loaded successfully.\")\n",
    "print(f\"Shape after dropping duplicates: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8937ad71-6353-4ca4-86dd-6e4ade51ee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1B. EXCLUDE EXPIRED AND HOSPICE PATIENTS\n",
    "# ==========================================\n",
    "print(\"\\n>>> STEP 1B: Excluding Expired and Hospice patients...\")\n",
    "exclude_discharge_ids = [11, 13, 14, 19, 20, 21]\n",
    "before_count = len(df)\n",
    "df = df[~df['discharge_disposition_id'].isin(exclude_discharge_ids)]\n",
    "after_count = len(df)\n",
    "print(f\"  Excluded {before_count - after_count} samples (Expired/Hospice)\")\n",
    "print(f\"  Remaining samples: {after_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369814da-4fcc-4347-952c-0dcc5e362e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2. FEATURE ENGINEERING\n",
    "# ==========================================\n",
    "print(\"\\n>>> STEP 2: Performing Feature Engineering...\")\n",
    "\n",
    "# ==========================================\n",
    "# 2A. ICD-9 CODE FEATURE EXTRACTION\n",
    "# ==========================================\n",
    "diag_cols = [\"diag_1\", \"diag_2\", \"diag_3\"]\n",
    "\n",
    "def normalize_icd(code):\n",
    "    \"\"\"Normalize ICD-9 code into a clean string (None if invalid).\"\"\"\n",
    "    if pd.isna(code):\n",
    "        return None\n",
    "    c = str(code).strip()\n",
    "    if c == \"\" or c.lower() == \"nan\":\n",
    "        return None\n",
    "    return c\n",
    "\n",
    "def build_diag_list(row):\n",
    "    \"\"\"Build a normalized list of ICD-9 codes for a given row.\"\"\"\n",
    "    return [normalize_icd(row[c]) for c in diag_cols]\n",
    "\n",
    "def has_icd_any(diag_list, icd_set):\n",
    "    \"\"\"\n",
    "    Check if any ICD-9 code in diag_list matches icd_set.\n",
    "    Match is based on exact code or main part before dot.\n",
    "    \"\"\"\n",
    "    for code in diag_list:\n",
    "        if code is None:\n",
    "            continue\n",
    "        main = code.split(\".\")[0]\n",
    "        if code in icd_set or main in icd_set:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "# === ICD-9 Code Sets (per project instructions) ===\n",
    "alcohol_codes = {\"303\", \"305\", \"571\", \"571.1\", \"571.2\", \"571.3\"}\n",
    "bp_codes = {\"401\", \"402\", \"403\", \"404\", \"405\", \"642\"}\n",
    "cholesterol_codes = {\"272\"}\n",
    "heart_codes = {\"410\", \"411\", \"412\", \"413\", \"414\", \"428\"}\n",
    "obesity_codes = {\"278\"}\n",
    "pregnancy_codes = {\n",
    "    \"630\", \"631\", \"632\", \"633\", \"634\", \"635\", \"636\", \"637\", \"638\", \"639\",\n",
    "    \"640\", \"641\", \"642\", \"643\", \"644\", \"645\", \"646\", \"647\", \"648\", \"649\"\n",
    "}\n",
    "uric_acid_codes = {\"274\", \"790.6\", \"790\"}\n",
    "vision_codes = {\"368\"}\n",
    "\n",
    "# Precompute each row's diagnosis list\n",
    "diag_lists = df.apply(build_diag_list, axis=1)\n",
    "\n",
    "# Create binary features from ICD-9 codes\n",
    "df[\"alcohol\"] = diag_lists.apply(lambda dl: has_icd_any(dl, alcohol_codes))\n",
    "df[\"blood_pressure\"] = diag_lists.apply(lambda dl: has_icd_any(dl, bp_codes))\n",
    "df[\"cholesterol\"] = diag_lists.apply(lambda dl: has_icd_any(dl, cholesterol_codes))\n",
    "df[\"heart_disease\"] = diag_lists.apply(lambda dl: has_icd_any(dl, heart_codes))\n",
    "df[\"obesity\"] = diag_lists.apply(lambda dl: has_icd_any(dl, obesity_codes))\n",
    "df[\"pregnancy\"] = diag_lists.apply(lambda dl: has_icd_any(dl, pregnancy_codes))\n",
    "df[\"uric_acid\"] = diag_lists.apply(lambda dl: has_icd_any(dl, uric_acid_codes))\n",
    "df[\"blurred_vision\"] = diag_lists.apply(lambda dl: has_icd_any(dl, vision_codes))\n",
    "\n",
    "print(\"ICD-9 based clinical features created:\")\n",
    "print(f\"  - alcohol:        {df['alcohol'].sum()} positive cases\")\n",
    "print(f\"  - blood_pressure: {df['blood_pressure'].sum()} positive cases\")\n",
    "print(f\"  - cholesterol:    {df['cholesterol'].sum()} positive cases\")\n",
    "print(f\"  - heart_disease:  {df['heart_disease'].sum()} positive cases\")\n",
    "print(f\"  - obesity:        {df['obesity'].sum()} positive cases\")\n",
    "print(f\"  - pregnancy:      {df['pregnancy'].sum()} positive cases\")\n",
    "print(f\"  - uric_acid:      {df['uric_acid'].sum()} positive cases\")\n",
    "print(f\"  - blurred_vision: {df['blurred_vision'].sum()} positive cases\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a213905-4b58-4e28-83f8-c82ce990f759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. TARGET VARIABLE CREATION (Diabetes Type 2)\n",
    "# ==========================================\n",
    "print(\"\\n>>> STEP 3: Creating Target Variable 'diabetes2'...\")\n",
    "\n",
    "def is_type2_diabetes_code(code):\n",
    "    \"\"\"\n",
    "    Check if an ICD-9 code is Type 2 diabetes pattern: 250.x0 or 250.x2.\n",
    "    Note: 250.x0 is equivalent to 250.x (trailing zero removed)\n",
    "          250 alone is equivalent to 250.00 (Type 2)\n",
    "    \"\"\"\n",
    "    code = normalize_icd(code)\n",
    "    if code is None:\n",
    "        return False\n",
    "    \n",
    "    # Case 1: exactly \"250\" -> equivalent to 250.00 (Type 2)\n",
    "    if code == \"250\":\n",
    "        return True\n",
    "    \n",
    "    if not code.startswith(\"250.\"):\n",
    "        return False\n",
    "    \n",
    "    tail = code.split(\".\")[1]\n",
    "    \n",
    "    # Case 2: 250.x (one digit) -> equivalent to 250.x0 (Type 2)\n",
    "    if len(tail) == 1:\n",
    "        return True\n",
    "    \n",
    "    # Case 3: 250.xy (two digits) -> Type 2 if y is 0 or 2\n",
    "    if len(tail) >= 2:\n",
    "        return tail[1] in {\"0\", \"2\"}\n",
    "    \n",
    "    return False\n",
    "\n",
    "def is_diabetes_250_any(code):\n",
    "    \"\"\"\n",
    "    Check if code is 250 or any 250.x pattern.\n",
    "    \"\"\"\n",
    "    code = normalize_icd(code)\n",
    "    if code is None:\n",
    "        return False\n",
    "    return code == \"250\" or code.startswith(\"250.\")\n",
    "\n",
    "def define_target(row):\n",
    "    \"\"\"\n",
    "    Define Type 2 diabetes target based on project rules:\n",
    "    - Condition 1: At least one diagnosis is 250.x0 or 250.x2.\n",
    "    - OR Condition 2: Diagnosis includes 250 or 250.x, AND \n",
    "      at least one diabetes medication (metformin, glimepiride, glipizide) is prescribed.\n",
    "    \n",
    "    Medication is considered prescribed if value is 'Up', 'Down', or 'Steady' (not 'No').\n",
    "    \"\"\"\n",
    "    diags = [row[c] for c in diag_cols]\n",
    "    \n",
    "    # Diabetes meds of interest (prescribed if not \"No\")\n",
    "    meds = [row[\"metformin\"], row[\"glimepiride\"], row[\"glipizide\"]]\n",
    "    meds_prescribed = any(m in [\"Up\", \"Down\", \"Steady\"] for m in meds if pd.notna(m))\n",
    "    \n",
    "    # Condition 1: Direct Type 2 code\n",
    "    if any(is_type2_diabetes_code(d) for d in diags):\n",
    "        return 1\n",
    "    \n",
    "    # Condition 2: Any diabetes code + medication prescribed\n",
    "    if meds_prescribed and any(is_diabetes_250_any(d) for d in diags):\n",
    "        return 1\n",
    "    \n",
    "    return 0\n",
    "\n",
    "df[\"diabetes2\"] = df.apply(define_target, axis=1)\n",
    "\n",
    "# Summary statistics\n",
    "total_positive = df[\"diabetes2\"].sum()\n",
    "total_negative = len(df) - total_positive\n",
    "prevalence = total_positive / len(df) * 100\n",
    "\n",
    "print(f\"Target variable 'diabetes2' created.\")\n",
    "print(f\"  - Total samples:    {len(df)}\")\n",
    "print(f\"  - Positive (1):     {total_positive} ({prevalence:.2f}%)\")\n",
    "print(f\"  - Negative (0):     {total_negative} ({100-prevalence:.2f}%)\")\n",
    "print(f\"  - Class imbalance ratio: 1:{total_negative/total_positive:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195c174a-f10e-4ae6-8995-5c8c61d5e889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 4. DEMOGRAPHICS PROCESSING (Age, Gender, Race)\n",
    "# ==========================================\n",
    "print(\"\\n>>> STEP 4: Processing Demographics (Age, Gender, Race)...\")\n",
    "\n",
    "# ---- AGE ----\n",
    "# Convert age intervals into ordered integer groups 0-9\n",
    "age_map = {\n",
    "    \"[0-10)\": 0, \"[10-20)\": 1, \"[20-30)\": 2, \"[30-40)\": 3, \"[40-50)\": 4,\n",
    "    \"[50-60)\": 5, \"[60-70)\": 6, \"[70-80)\": 7, \"[80-90)\": 8, \"[90-100)\": 9\n",
    "}\n",
    "\n",
    "# Check for invalid age values before filtering\n",
    "invalid_age = df[~df[\"age\"].isin(age_map.keys())][\"age\"].unique()\n",
    "if len(invalid_age) > 0:\n",
    "    print(f\"  - Removing {len(df[~df['age'].isin(age_map.keys())])} rows with invalid age: {invalid_age}\")\n",
    "\n",
    "# Keep only rows where age is valid\n",
    "df = df[df[\"age\"].isin(age_map.keys())]\n",
    "df[\"age\"] = df[\"age\"].map(age_map)\n",
    "\n",
    "print(f\"  - Age encoded (0-9). Distribution:\")\n",
    "print(df[\"age\"].value_counts().sort_index().to_string())\n",
    "\n",
    "# ---- GENDER ----\n",
    "# Remove rows with invalid gender values\n",
    "valid_genders = {\"Male\", \"Female\"}\n",
    "invalid_gender = df[~df[\"gender\"].isin(valid_genders)][\"gender\"].unique()\n",
    "if len(invalid_gender) > 0:\n",
    "    print(f\"\\n  - Removing {len(df[~df['gender'].isin(valid_genders)])} rows with invalid gender: {invalid_gender}\")\n",
    "\n",
    "df = df[df[\"gender\"].isin(valid_genders)]\n",
    "# Map gender: Male=1, Female=0\n",
    "df[\"gender\"] = df[\"gender\"].map({\"Male\": 1, \"Female\": 0})\n",
    "\n",
    "print(f\"\\n  - Gender encoded. Distribution:\")\n",
    "print(f\"    Male (1):   {(df['gender']==1).sum()}\")\n",
    "print(f\"    Female (0): {(df['gender']==0).sum()}\")\n",
    "\n",
    "# ---- RACE ----\n",
    "# Normalize race categories: 1-Caucasian, 2-African American, 3-Asian, 4-Hispanic, 5-Others\n",
    "def encode_race(x):\n",
    "    if x == \"Caucasian\":\n",
    "        return 1\n",
    "    elif x == \"AfricanAmerican\":\n",
    "        return 2\n",
    "    elif x == \"Asian\":\n",
    "        return 3\n",
    "    elif x == \"Hispanic\":\n",
    "        return 4\n",
    "    else:\n",
    "        # Includes 'Other', missing, unknown values\n",
    "        return 5\n",
    "\n",
    "df[\"race\"] = df[\"race\"].apply(encode_race)\n",
    "\n",
    "print(f\"\\n  - Race encoded. Distribution:\")\n",
    "print(f\"    1-Caucasian:        {(df['race']==1).sum()}\")\n",
    "print(f\"    2-African American: {(df['race']==2).sum()}\")\n",
    "print(f\"    3-Asian:            {(df['race']==3).sum()}\")\n",
    "print(f\"    4-Hispanic:         {(df['race']==4).sum()}\")\n",
    "print(f\"    5-Others:           {(df['race']==5).sum()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab7c921-7862-4dba-8e38-5a1100fd6937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 5. FINAL DATA SELECTION & TRAIN-TEST SPLIT\n",
    "# ==========================================\n",
    "print(\"\\n>>> STEP 5: Finalizing Dataset for Modeling...\")\n",
    "\n",
    "# ==========================================\n",
    "# 5A. DEFINE FEATURE COLUMNS\n",
    "# ==========================================\n",
    "# 11 base features (per project requirement) + 3 interaction features\n",
    "feature_cols = [\n",
    "    # Demographics (3)\n",
    "    \"race\", \"gender\", \"age\",\n",
    "    # ICD-9 based clinical features (8)\n",
    "    \"alcohol\", \"blood_pressure\", \"cholesterol\", \"heart_disease\",\n",
    "    \"obesity\", \"pregnancy\", \"uric_acid\", \"blurred_vision\"\n",
    "]\n",
    "\n",
    "target_col = \"diabetes2\"\n",
    "\n",
    "print(f\"Features selected ({len(feature_cols)} total):\")\n",
    "print(f\" - Demographics (3): race, gender, age\")\n",
    "print(f\" - Clinical features (8): alcohol, blood_pressure, cholesterol,\")\n",
    "print(f\"   heart_disease, obesity, pregnancy, uric_acid, blurred_vision\")\n",
    "print(f\" - Target: {target_col}\")\n",
    "\n",
    "# ==========================================\n",
    "# 5B. EXTRACT FEATURES AND TARGET\n",
    "# ==========================================\n",
    "X = df[feature_cols].copy()\n",
    "y = df[target_col].astype(int).copy()\n",
    "\n",
    "# Check for missing values\n",
    "missing_count = X.isnull().sum().sum()\n",
    "if missing_count > 0:\n",
    "    print(f\"\\n  WARNING: {missing_count} missing values found in features.\")\n",
    "    # Drop rows with missing values\n",
    "    combined = pd.concat([X, y], axis=1).dropna()\n",
    "    X = combined[feature_cols]\n",
    "    y = combined[target_col].astype(int)\n",
    "    print(f\"  Dropped rows with missing values. New shape: {X.shape}\")\n",
    "else:\n",
    "    print(f\"\\n  No missing values in features. Shape: {X.shape}\")\n",
    "\n",
    "# ==========================================\n",
    "# 5C. CLASS BALANCE SUMMARY\n",
    "# ==========================================\n",
    "print(f\"\\nClass distribution in final dataset:\")\n",
    "print(f\"  - Class 0 (No diabetes2): {(y==0).sum()} ({(y==0).mean()*100:.2f}%)\")\n",
    "print(f\"  - Class 1 (Diabetes2):    {(y==1).sum()} ({(y==1).mean()*100:.2f}%)\")\n",
    "\n",
    "# ==========================================\n",
    "# 5D. TRAIN-TEST SPLIT\n",
    "# ==========================================\n",
    "# 80% train, 20% test, stratified to preserve class proportions\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain-Test Split (80/20, stratified):\")\n",
    "print(f\"  - Train set: {X_train.shape[0]} samples\")\n",
    "print(f\"    - Class 0: {(y_train==0).sum()} ({(y_train==0).mean()*100:.2f}%)\")\n",
    "print(f\"    - Class 1: {(y_train==1).sum()} ({(y_train==1).mean()*100:.2f}%)\")\n",
    "print(f\"  - Test set:  {X_test.shape[0]} samples\")\n",
    "print(f\"    - Class 0: {(y_test==0).sum()} ({(y_test==0).mean()*100:.2f}%)\")\n",
    "print(f\"    - Class 1: {(y_test==1).sum()} ({(y_test==1).mean()*100:.2f}%)\")\n",
    "\n",
    "# ==========================================\n",
    "# 5E. FEATURE SUMMARY TABLE\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE SUMMARY TABLE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Feature':<25} {'Type':<12} {'Min':>6} {'Max':>6} {'Mean':>8}\")\n",
    "print(\"-\"*60)\n",
    "for col in feature_cols:\n",
    "    col_type = \"Binary\" if X[col].nunique() <= 2 else \"Ordinal\"\n",
    "    print(f\"{col:<25} {col_type:<12} {X[col].min():>6.0f} {X[col].max():>6.0f} {X[col].mean():>8.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5aa789-953a-4dcd-8c2f-4a23e6406e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 5F. DESCRIPTIVE ANALYSIS \n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\">>> STEP 5F: DESCRIPTIVE ANALYSIS OF FEATURES\")\n",
    "print(\"=\"*80)\n",
    "print(\"(This section demonstrates data preprocessing was done correctly)\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 5F-1. Basic Information of Sample\n",
    "# ---------------------------------------------\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"5F-1. SAMPLE CHARACTERISTICS\")\n",
    "print(\"-\"*60)\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Total features: {len(feature_cols)}\")\n",
    "print(f\"Target variable: diabetes2\")\n",
    "print(f\"  - Positive (Type 2 Diabetes): {(y==1).sum()} ({(y==1).mean()*100:.2f}%)\")\n",
    "print(f\"  - Negative (No Diabetes): {(y==0).sum()} ({(y==0).mean()*100:.2f}%)\")\n",
    "print(f\"  - Imbalance Ratio: 1:{(y==0).sum()/(y==1).sum():.2f}\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 5F-2. Distribution of Demographic Characteristics\n",
    "# ---------------------------------------------\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"5F-2. DEMOGRAPHIC FEATURES DISTRIBUTION\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# Age distribution\n",
    "print(\"\\n[Age Distribution]\")\n",
    "age_dist = df.groupby('age').agg({\n",
    "    'diabetes2': ['count', 'sum', 'mean']\n",
    "}).round(4)\n",
    "age_dist.columns = ['Total', 'Diabetes_Count', 'Diabetes_Rate']\n",
    "age_labels = ['[0-10)', '[10-20)', '[20-30)', '[30-40)', '[40-50)', \n",
    "              '[50-60)', '[60-70)', '[70-80)', '[80-90)', '[90-100)']\n",
    "age_dist.index = [age_labels[i] for i in age_dist.index]\n",
    "print(age_dist.to_string())\n",
    "\n",
    "# Gender distribution\n",
    "print(\"\\n[Gender Distribution]\")\n",
    "gender_dist = df.groupby('gender').agg({\n",
    "    'diabetes2': ['count', 'sum', 'mean']\n",
    "}).round(4)\n",
    "gender_dist.columns = ['Total', 'Diabetes_Count', 'Diabetes_Rate']\n",
    "gender_dist.index = ['Female', 'Male']\n",
    "print(gender_dist.to_string())\n",
    "\n",
    "# Race distribution\n",
    "print(\"\\n[Race Distribution]\")\n",
    "race_dist = df.groupby('race').agg({\n",
    "    'diabetes2': ['count', 'sum', 'mean']\n",
    "}).round(4)\n",
    "race_dist.columns = ['Total', 'Diabetes_Count', 'Diabetes_Rate']\n",
    "race_labels = {1: 'Caucasian', 2: 'African American', 3: 'Asian', 4: 'Hispanic', 5: 'Others'}\n",
    "race_dist.index = [race_labels[i] for i in race_dist.index]\n",
    "print(race_dist.to_string())\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 5F-3. Distribution of Clinical Features（ICD-9 based）\n",
    "# ---------------------------------------------\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"5F-3. CLINICAL FEATURES DISTRIBUTION (ICD-9 Based)\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "clinical_features = ['alcohol', 'blood_pressure', 'cholesterol', 'heart_disease', \n",
    "                     'obesity', 'pregnancy', 'uric_acid', 'blurred_vision']\n",
    "\n",
    "clinical_summary = []\n",
    "for feat in clinical_features:\n",
    "    total_positive = df[feat].sum()\n",
    "    diabetes_with_feat = df[df[feat]==1]['diabetes2'].sum()\n",
    "    diabetes_rate_with = df[df[feat]==1]['diabetes2'].mean() if total_positive > 0 else 0\n",
    "    diabetes_rate_without = df[df[feat]==0]['diabetes2'].mean()\n",
    "    \n",
    "    clinical_summary.append({\n",
    "        'Feature': feat,\n",
    "        'Positive_Cases': total_positive,\n",
    "        'Prevalence(%)': total_positive/len(df)*100,\n",
    "        'Diabetes_Rate_With(%)': diabetes_rate_with*100,\n",
    "        'Diabetes_Rate_Without(%)': diabetes_rate_without*100,\n",
    "        'Relative_Risk': diabetes_rate_with/diabetes_rate_without if diabetes_rate_without > 0 else 0\n",
    "    })\n",
    "\n",
    "clinical_df = pd.DataFrame(clinical_summary)\n",
    "print(clinical_df.to_string(index=False))\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 5F-4. The Correlation Between Features and Target Variables\n",
    "# ---------------------------------------------\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"5F-4. FEATURE-TARGET CORRELATION\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "correlations = X.corrwith(y).sort_values(ascending=False)\n",
    "print(\"\\nCorrelation with diabetes2 (sorted):\")\n",
    "for feat, corr in correlations.items():\n",
    "    print(f\"  {feat:<25}: {corr:>8.4f}\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 5F-5. Descriptive Statistical Visualization\n",
    "# ---------------------------------------------\n",
    "print(\"\\n>>> Generating Descriptive Analysis Figures...\")\n",
    "\n",
    "# Figure 1: Distribution of target variables (pie chart)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# 1a. Target variable distribution\n",
    "labels = ['Non-Diabetic', 'Type 2 Diabetic']\n",
    "sizes = [(y==0).sum(), (y==1).sum()]\n",
    "colors = ['#66b3ff', '#ff6666']\n",
    "axes[0].pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "axes[0].set_title('Target Variable Distribution\\n(diabetes2)', fontsize=12)\n",
    "\n",
    "# 1b. Age distribution with diabetes rate\n",
    "age_counts = df.groupby('age').size()\n",
    "diabetes_rates = df.groupby('age')['diabetes2'].mean() * 100\n",
    "ax1b = axes[1]\n",
    "ax1b_twin = ax1b.twinx()\n",
    "bars = ax1b.bar(range(len(age_counts)), age_counts.values, color='steelblue', alpha=0.7, label='Count')\n",
    "line = ax1b_twin.plot(range(len(age_counts)), diabetes_rates.values, 'r-o', linewidth=2, label='Diabetes Rate')\n",
    "ax1b.set_xlabel('Age Group')\n",
    "ax1b.set_ylabel('Count', color='steelblue')\n",
    "ax1b_twin.set_ylabel('Diabetes Rate (%)', color='red')\n",
    "ax1b.set_xticks(range(len(age_counts)))\n",
    "ax1b.set_xticklabels(['0-10', '10-20', '20-30', '30-40', '40-50', '50-60', '60-70', '70-80', '80-90', '90+'], rotation=45)\n",
    "ax1b.set_title('Age Distribution & Diabetes Rate', fontsize=12)\n",
    "\n",
    "# 1c. Clinical features prevalence\n",
    "feat_names = ['alcohol', 'blood_pr', 'cholest', 'heart_dis', 'obesity', 'pregn', 'uric_ac', 'blur_vis']\n",
    "feat_prevalence = [df[f].mean()*100 for f in clinical_features]\n",
    "axes[2].barh(feat_names, feat_prevalence, color='teal')\n",
    "axes[2].set_xlabel('Prevalence (%)')\n",
    "axes[2].set_title('Clinical Features Prevalence', fontsize=12)\n",
    "for i, v in enumerate(feat_prevalence):\n",
    "    axes[2].text(v + 0.5, i, f'{v:.1f}%', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('descriptive_analysis_1.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: descriptive_analysis_1.png\")\n",
    "\n",
    "# Figure 2: Feature correlation heat map\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = X.corr()\n",
    "import seaborn as sns\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='RdBu_r', center=0, \n",
    "            fmt='.2f', square=True, linewidths=0.5)\n",
    "plt.title('Feature Correlation Matrix', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: correlation_heatmap.png\")\n",
    "\n",
    "# Figure 3: Comparison of diabetes rates for each clinical feature\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feat in enumerate(clinical_features):\n",
    "    ax = axes[i]\n",
    "    # The rate of diabetes with and without this feature\n",
    "    rates = [\n",
    "        df[df[feat]==0]['diabetes2'].mean() * 100,\n",
    "        df[df[feat]==1]['diabetes2'].mean() * 100\n",
    "    ]\n",
    "    bars = ax.bar(['Without', 'With'], rates, color=['#3498db', '#e74c3c'])\n",
    "    ax.set_title(feat.replace('_', ' ').title(), fontsize=11)\n",
    "    ax.set_ylabel('Diabetes Rate (%)')\n",
    "    ax.set_ylim(0, max(rates)*1.3 if max(rates) > 0 else 30)\n",
    "    for bar, rate in zip(bars, rates):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                f'{rate:.1f}%', ha='center', fontsize=9)\n",
    "\n",
    "plt.suptitle('Diabetes Rate by Clinical Feature Presence', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('clinical_features_diabetes_rate.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: clinical_features_diabetes_rate.png\")\n",
    "\n",
    "print(\"\\n>>> Descriptive Analysis complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0679711f-a8a9-4079-b3b2-9fd388bb483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 6. MODEL TRAINING AND EVALUATION\n",
    "# ==========================================\n",
    "print(\"\\n>>> STEP 6: Model Training...\")\n",
    "\n",
    "# ==========================================\n",
    "# 6A. DEFINE EVALUATION HELPER FUNCTION & CV STRATEGIES\n",
    "# ==========================================\n",
    "\n",
    "# Define cross-validation strategies (used consistently across all models)\n",
    "cv_5fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "cv_10fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "print(\"Cross-validation strategies defined:\")\n",
    "print(\"  - 5-fold: for hyperparameter tuning (GridSearchCV)\")\n",
    "print(\"  - 10-fold: for final model evaluation (paper-style)\")\n",
    "\n",
    "def evaluate_model(name, y_true, y_pred, y_proba, print_results=True):\n",
    "    \"\"\"\n",
    "    Comprehensive model evaluation function.\n",
    "    Returns a dictionary with all metrics for later comparison.\n",
    "    \"\"\"\n",
    "    # Confusion Matrix components\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    roc_auc = roc_auc_score(y_true, y_proba)\n",
    "    pr_auc = average_precision_score(y_true, y_proba)\n",
    "    \n",
    "    # Specificity (True Negative Rate)\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    \n",
    "    # Store results\n",
    "    results = {\n",
    "        \"name\": name,\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1_score\": f1,\n",
    "        \"specificity\": specificity,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"pr_auc\": pr_auc,\n",
    "        \"tn\": tn, \"fp\": fp, \"fn\": fn, \"tp\": tp,\n",
    "        \"y_pred\": y_pred,\n",
    "        \"y_proba\": y_proba\n",
    "    }\n",
    "    \n",
    "    if print_results:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\" {name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"\\nConfusion Matrix:\")\n",
    "        print(f\"                 Predicted\")\n",
    "        print(f\"                 Neg    Pos\")\n",
    "        print(f\"  Actual Neg    {tn:>5}  {fp:>5}   (TN, FP)\")\n",
    "        print(f\"  Actual Pos    {fn:>5}  {tp:>5}   (FN, TP)\")\n",
    "        print(f\"\\nMetrics:\")\n",
    "        print(f\"  Accuracy:    {acc:.4f}\")\n",
    "        print(f\"  Precision:   {prec:.4f}\")\n",
    "        print(f\"  Recall:      {rec:.4f}\")\n",
    "        print(f\"  F1-Score:    {f1:.4f}\")\n",
    "        print(f\"  Specificity: {specificity:.4f}\")\n",
    "        print(f\"  ROC AUC:     {roc_auc:.4f}\")\n",
    "        print(f\"  PR AUC:      {pr_auc:.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Dictionary to store all model results (test set evaluation)\n",
    "all_results = {}\n",
    "\n",
    "# Dictionary to store trained models (for SHAP analysis later)\n",
    "trained_models = {}\n",
    "\n",
    "print(\"\\nEvaluation function defined. Ready for model training.\")\n",
    "\n",
    "# ==========================================\n",
    "# 6A-2. FEATURE SELECTION ANALYSIS\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\">>> STEP 6A-2: FEATURE SELECTION ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, chi2\n",
    "\n",
    "# method1: Information Gain (Mutual Information)\n",
    "print(\"\\n--- Method 1: Information Gain (Mutual Information) ---\")\n",
    "mi_selector = SelectKBest(score_func=mutual_info_classif, k='all')\n",
    "mi_selector.fit(X_train, y_train)\n",
    "mi_scores = pd.Series(mi_selector.scores_, index=feature_cols).sort_values(ascending=False)\n",
    "\n",
    "# method2: Chi-squared Test\n",
    "print(\"--- Method 2: Chi-squared Test ---\")\n",
    "chi2_selector = SelectKBest(score_func=chi2, k='all')\n",
    "chi2_selector.fit(X_train, y_train)\n",
    "chi2_scores = pd.Series(chi2_selector.scores_, index=feature_cols).sort_values(ascending=False)\n",
    "\n",
    "# method3: Random Forest Feature Importance \n",
    "print(\"--- Method 3: Random Forest Importance ---\")\n",
    "rf_for_fs = RandomForestClassifier(n_estimators=100, class_weight='balanced', \n",
    "                                    random_state=RANDOM_SEED, n_jobs=-1)\n",
    "rf_for_fs.fit(X_train, y_train)\n",
    "rf_importance = pd.Series(rf_for_fs.feature_importances_, index=feature_cols).sort_values(ascending=False)\n",
    "\n",
    "# method4: Correlation with Target\n",
    "print(\"--- Method 4: Correlation with Target ---\")\n",
    "corr_scores = X_train.corrwith(y_train).abs().sort_values(ascending=False)\n",
    "\n",
    "# Summary table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE SELECTION RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "fs_summary = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'MI_Score': mi_scores.reindex(feature_cols).values,\n",
    "    'Chi2_Score': chi2_scores.reindex(feature_cols).values,\n",
    "    'RF_Importance': rf_importance.reindex(feature_cols).values,\n",
    "    'Correlation': corr_scores.reindex(feature_cols).values\n",
    "})\n",
    "\n",
    "# Calculate the average ranking\n",
    "for col in ['MI_Score', 'Chi2_Score', 'RF_Importance', 'Correlation']:\n",
    "    fs_summary[f'{col}_Rank'] = fs_summary[col].rank(ascending=False)\n",
    "\n",
    "fs_summary['Avg_Rank'] = fs_summary[['MI_Score_Rank', 'Chi2_Score_Rank', \n",
    "                                      'RF_Importance_Rank', 'Correlation_Rank']].mean(axis=1)\n",
    "fs_summary = fs_summary.sort_values('Avg_Rank')\n",
    "\n",
    "print(fs_summary[['Feature', 'MI_Score', 'Chi2_Score', 'RF_Importance', 'Correlation', 'Avg_Rank']].to_string(index=False))\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "# MI Scores\n",
    "axes[0].barh(mi_scores.index[::-1], mi_scores.values[::-1], color='steelblue')\n",
    "axes[0].set_title('Information Gain', fontsize=12)\n",
    "axes[0].set_xlabel('MI Score')\n",
    "\n",
    "# Chi2 Scores\n",
    "axes[1].barh(chi2_scores.index[::-1], chi2_scores.values[::-1], color='coral')\n",
    "axes[1].set_title('Chi-squared Score', fontsize=12)\n",
    "axes[1].set_xlabel('Chi2 Score')\n",
    "\n",
    "# RF Importance\n",
    "axes[2].barh(rf_importance.index[::-1], rf_importance.values[::-1], color='forestgreen')\n",
    "axes[2].set_title('Random Forest Importance', fontsize=12)\n",
    "axes[2].set_xlabel('Importance')\n",
    "\n",
    "# Correlation\n",
    "axes[3].barh(corr_scores.index[::-1], corr_scores.values[::-1], color='purple')\n",
    "axes[3].set_title('Correlation with Target', fontsize=12)\n",
    "axes[3].set_xlabel('|Correlation|')\n",
    "\n",
    "plt.suptitle('Feature Selection Methods Comparison', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_selection_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\nSaved: feature_selection_comparison.png\")\n",
    "\n",
    "print(\"\\n>>> Feature Selection Analysis complete.\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 6B. BASELINE MODEL: Random Forest\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\">>> STEP 6B: Training Baseline Random Forest...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "rf_baseline = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=2,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_baseline.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf_base = rf_baseline.predict(X_test)\n",
    "y_proba_rf_base = rf_baseline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "all_results[\"RF_Baseline\"] = evaluate_model(\n",
    "    \"Baseline Random Forest\", \n",
    "    y_test, y_pred_rf_base, y_proba_rf_base\n",
    ")\n",
    "\n",
    "trained_models[\"RF_Baseline\"] = rf_baseline\n",
    "\n",
    "print(\"\\n>>> Baseline Random Forest complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9727138-64b2-4fa0-92ba-dae1657b6721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 6C. TUNED MODEL: Random Forest with GridSearchCV\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\">>> STEP 6C: Tuning Random Forest (GridSearchCV, 5-fold)...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "param_grid_rf = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [6, 8, 10, 12],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_for_tuning = RandomForestClassifier(\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=rf_for_tuning,\n",
    "    param_grid=param_grid_rf,\n",
    "    scoring=\"f1\",\n",
    "    cv=cv_5fold,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nBest parameters: {grid_search_rf.best_params_}\")\n",
    "print(f\"Best CV F1 score: {grid_search_rf.best_score_:.4f}\")\n",
    "\n",
    "rf_tuned = grid_search_rf.best_estimator_\n",
    "\n",
    "y_pred_rf_tuned = rf_tuned.predict(X_test)\n",
    "y_proba_rf_tuned = rf_tuned.predict_proba(X_test)[:, 1]\n",
    "\n",
    "all_results[\"RF_Tuned\"] = evaluate_model(\n",
    "    \"Tuned Random Forest\",\n",
    "    y_test, y_pred_rf_tuned, y_proba_rf_tuned\n",
    ")\n",
    "\n",
    "trained_models[\"RF_Tuned\"] = rf_tuned\n",
    "\n",
    "print(\"\\n>>> Tuned Random Forest complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e04823-c6dc-40ca-84f0-a0b209712ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 6D. ADVANCED MODEL: XGBoost\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\">>> STEP 6D: Training XGBoost...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Compute scale_pos_weight to handle class imbalance\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"Class imbalance ratio (scale_pos_weight): {scale_pos_weight:.2f}\")\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_jobs=-1,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "y_proba_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "all_results[\"XGBoost\"] = evaluate_model(\n",
    "    \"XGBoost\",\n",
    "    y_test, y_pred_xgb, y_proba_xgb\n",
    ")\n",
    "\n",
    "trained_models[\"XGBoost\"] = xgb_model\n",
    "\n",
    "print(\"\\n>>> XGBoost complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33826a8-5f2d-4cb9-9fe4-d199191b0225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 6E. ADVANCED MODEL: LightGBM\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\">>> STEP 6E: Training LightGBM...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "lgb_model = LGBMClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "y_proba_lgb = lgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "all_results[\"LightGBM\"] = evaluate_model(\n",
    "    \"LightGBM\",\n",
    "    y_test, y_pred_lgb, y_proba_lgb\n",
    ")\n",
    "\n",
    "trained_models[\"LightGBM\"] = lgb_model\n",
    "\n",
    "print(\"\\n>>> LightGBM complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce31002-6644-4290-831d-21e740c72a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 6F. BASELINE MODEL: Logistic Regression\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\">>> STEP 6F: Training Logistic Regression...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "lr_model = LogisticRegression(\n",
    "    class_weight=\"balanced\",\n",
    "    solver=\"liblinear\",\n",
    "    max_iter=1000,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "y_proba_lr = lr_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "all_results[\"LogisticRegression\"] = evaluate_model(\n",
    "    \"Logistic Regression\",\n",
    "    y_test, y_pred_lr, y_proba_lr\n",
    ")\n",
    "\n",
    "trained_models[\"LogisticRegression\"] = lr_model\n",
    "\n",
    "print(\"\\n>>> Logistic Regression complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faf14cb-ac2f-49ea-8a99-f734e4967dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 6G. MODEL: K-Nearest Neighbors (KNN)\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\">>> STEP 6G: Training KNN...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# KNN requires feature scaling\n",
    "knn_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"knn\", KNeighborsClassifier(n_neighbors=11, n_jobs=-1))\n",
    "])\n",
    "\n",
    "knn_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = knn_pipeline.predict(X_test)\n",
    "y_proba_knn = knn_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "all_results[\"KNN\"] = evaluate_model(\n",
    "    \"K-Nearest Neighbors (k=11)\",\n",
    "    y_test, y_pred_knn, y_proba_knn\n",
    ")\n",
    "\n",
    "trained_models[\"KNN\"] = knn_pipeline\n",
    "\n",
    "print(\"\\n>>> KNN complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703658f8-c4fa-4cb6-8b2f-cdd15d9704b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 6I. MODEL: Naive Bayes\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\">>> STEP 6I: Training Naive Bayes...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "y_proba_nb = nb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "all_results[\"NaiveBayes\"] = evaluate_model(\n",
    "    \"Naive Bayes\",\n",
    "    y_test, y_pred_nb, y_proba_nb\n",
    ")\n",
    "\n",
    "trained_models[\"NaiveBayes\"] = nb_model\n",
    "\n",
    "print(\"\\n>>> Naive Bayes complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf53c52-9af9-4bb4-b950-7dfef43062e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 6J. 10-FOLD CROSS-VALIDATION (ALL MODELS EXCEPT SVM)\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\">>> STEP 6J: 10-Fold Cross-Validation (Paper-style Evaluation)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Models to evaluate with 10-fold CV\n",
    "# Note: SVM excluded due to extremely long training time\n",
    "models_for_cv = {\n",
    "    \"RF_Baseline\": RandomForestClassifier(\n",
    "        n_estimators=300, max_depth=10, min_samples_leaf=2,\n",
    "        class_weight=\"balanced\", random_state=RANDOM_SEED, n_jobs=-1\n",
    "    ),\n",
    "    \"RF_Tuned\": RandomForestClassifier(\n",
    "        **grid_search_rf.best_params_,\n",
    "        class_weight=\"balanced\", random_state=RANDOM_SEED, n_jobs=-1\n",
    "    ),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        n_estimators=200, max_depth=6, learning_rate=0.1,\n",
    "        subsample=0.8, colsample_bytree=0.8,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        random_state=RANDOM_SEED, n_jobs=-1, verbosity=0\n",
    "    ),\n",
    "    \"LightGBM\": LGBMClassifier(\n",
    "        n_estimators=200, max_depth=6, learning_rate=0.05,\n",
    "        subsample=0.8, colsample_bytree=0.8,\n",
    "        class_weight=\"balanced\", random_state=RANDOM_SEED, n_jobs=-1, verbose=-1\n",
    "    ),\n",
    "    \"LogisticRegression\": LogisticRegression(\n",
    "        class_weight=\"balanced\", solver=\"liblinear\",\n",
    "        max_iter=1000, random_state=RANDOM_SEED\n",
    "    ),\n",
    "    \"KNN\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"knn\", KNeighborsClassifier(n_neighbors=11, n_jobs=-1))\n",
    "    ]),\n",
    "    # SVM excluded: too slow for 10-fold CV on this dataset\n",
    "    \"NaiveBayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Store CV results\n",
    "cv_results = {}\n",
    "\n",
    "print(\"\\nRunning 10-fold CV for all models (SVM excluded)...\\n\")\n",
    "\n",
    "for name, model in models_for_cv.items():\n",
    "    print(f\"  Evaluating {name}...\", end=\" \")\n",
    "    \n",
    "    # Accuracy\n",
    "    acc_scores = cross_val_score(model, X, y, cv=cv_10fold, scoring=\"accuracy\", n_jobs=-1)\n",
    "    \n",
    "    # F1-score\n",
    "    f1_scores = cross_val_score(model, X, y, cv=cv_10fold, scoring=\"f1\", n_jobs=-1)\n",
    "    \n",
    "    # Precision\n",
    "    prec_scores = cross_val_score(model, X, y, cv=cv_10fold, scoring=\"precision\", n_jobs=-1)\n",
    "    \n",
    "    # Recall\n",
    "    rec_scores = cross_val_score(model, X, y, cv=cv_10fold, scoring=\"recall\", n_jobs=-1)\n",
    "    \n",
    "    # ROC AUC\n",
    "    auc_scores = cross_val_score(model, X, y, cv=cv_10fold, scoring=\"roc_auc\", n_jobs=-1)\n",
    "    \n",
    "    cv_results[name] = {\n",
    "        \"accuracy_mean\": acc_scores.mean(),\n",
    "        \"accuracy_std\": acc_scores.std(),\n",
    "        \"f1_mean\": f1_scores.mean(),\n",
    "        \"f1_std\": f1_scores.std(),\n",
    "        \"precision_mean\": prec_scores.mean(),\n",
    "        \"precision_std\": prec_scores.std(),\n",
    "        \"recall_mean\": rec_scores.mean(),\n",
    "        \"recall_std\": rec_scores.std(),\n",
    "        \"roc_auc_mean\": auc_scores.mean(),\n",
    "        \"roc_auc_std\": auc_scores.std()\n",
    "    }\n",
    "    \n",
    "    print(f\"Done. F1={f1_scores.mean():.4f} (±{f1_scores.std():.4f})\")\n",
    "\n",
    "# Add SVM results from test set only (no CV)\n",
    "# Mark it separately so we know it's not from 10-fold CV\n",
    "print(\"\\n  Note: SVM evaluated on test set only (10-fold CV too slow)\")\n",
    "\n",
    "# ==========================================\n",
    "# PRINT CV RESULTS TABLE\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\" 10-FOLD CROSS-VALIDATION RESULTS SUMMARY\")\n",
    "print(\"=\"*90)\n",
    "print(f\"{'Model':<20} {'Accuracy':>14} {'Precision':>14} {'Recall':>14} {'F1-Score':>14} {'ROC AUC':>14}\")\n",
    "print(\"-\"*90)\n",
    "\n",
    "for name, res in cv_results.items():\n",
    "    print(f\"{name:<20} \"\n",
    "          f\"{res['accuracy_mean']:.4f}±{res['accuracy_std']:.4f} \"\n",
    "          f\"{res['precision_mean']:.4f}±{res['precision_std']:.4f} \"\n",
    "          f\"{res['recall_mean']:.4f}±{res['recall_std']:.4f} \"\n",
    "          f\"{res['f1_mean']:.4f}±{res['f1_std']:.4f} \"\n",
    "          f\"{res['roc_auc_mean']:.4f}±{res['roc_auc_std']:.4f}\")\n",
    "\n",
    "print(\"-\"*90)\n",
    "print(\"Note: SVM excluded from 10-fold CV due to computational time constraints.\")\n",
    "print(\"      SVM results available from test set evaluation (Step 6H).\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Find best model by F1\n",
    "best_model_name = max(cv_results, key=lambda x: cv_results[x][\"f1_mean\"])\n",
    "print(f\"\\nBest model by F1-score: {best_model_name} (F1 = {cv_results[best_model_name]['f1_mean']:.4f})\")\n",
    "\n",
    "print(\"\\n>>> 10-Fold Cross-Validation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055904ed-3c8a-426b-9dba-174c4dccf31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 7. COMPREHENSIVE MODEL EVALUATION\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\">>> STEP 7: Comprehensive Model Evaluation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ==========================================\n",
    "# 7A. TEST SET RESULTS SUMMARY TABLE\n",
    "# ==========================================\n",
    "print(\"\\n>>> STEP 7A: Test Set Evaluation Summary\")\n",
    "\n",
    "# List of models to summarize (excluding SVM)\n",
    "models_to_summarize = [\"RF_Baseline\", \"RF_Tuned\", \"XGBoost\", \"LightGBM\", \n",
    "                       \"LogisticRegression\", \"KNN\", \"NaiveBayes\"]\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\" TEST SET EVALUATION RESULTS (All Models)\")\n",
    "print(\"=\"*100)\n",
    "print(f\"{'Model':<20} {'Accuracy':>10} {'Precision':>10} {'Recall':>10} {'F1-Score':>10} {'Specificity':>12} {'ROC AUC':>10} {'PR AUC':>10}\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "for name in models_to_summarize:\n",
    "    if name in all_results:\n",
    "        res = all_results[name]\n",
    "        print(f\"{name:<20} \"\n",
    "              f\"{res['accuracy']:>10.4f} \"\n",
    "              f\"{res['precision']:>10.4f} \"\n",
    "              f\"{res['recall']:>10.4f} \"\n",
    "              f\"{res['f1_score']:>10.4f} \"\n",
    "              f\"{res['specificity']:>12.4f} \"\n",
    "              f\"{res['roc_auc']:>10.4f} \"\n",
    "              f\"{res['pr_auc']:>10.4f}\")\n",
    "\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Confusion Matrix Summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" CONFUSION MATRIX SUMMARY (TN, FP, FN, TP)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Model':<20} {'TN':>10} {'FP':>10} {'FN':>10} {'TP':>10}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for name in models_to_summarize:\n",
    "    if name in all_results:\n",
    "        res = all_results[name]\n",
    "        print(f\"{name:<20} \"\n",
    "              f\"{res['tn']:>10} \"\n",
    "              f\"{res['fp']:>10} \"\n",
    "              f\"{res['fn']:>10} \"\n",
    "              f\"{res['tp']:>10}\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Find best model by F1 on test set\n",
    "best_test_model = max(models_to_summarize, key=lambda x: all_results[x][\"f1_score\"] if x in all_results else 0)\n",
    "print(f\"\\nBest model on test set by F1-score: {best_test_model} (F1 = {all_results[best_test_model]['f1_score']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3176340-5f11-4388-afab-7e3d97c52d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 7B. ROC CURVES (ALL MODELS)\n",
    "# ==========================================\n",
    "print(\"\\n>>> STEP 7B: Plotting ROC Curves for All Models...\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Define colors for each model\n",
    "colors = {\n",
    "    \"RF_Baseline\": \"#1f77b4\",\n",
    "    \"RF_Tuned\": \"#ff7f0e\", \n",
    "    \"XGBoost\": \"#2ca02c\",\n",
    "    \"LightGBM\": \"#d62728\",\n",
    "    \"LogisticRegression\": \"#9467bd\",\n",
    "    \"KNN\": \"#8c564b\",\n",
    "    \"NaiveBayes\": \"#e377c2\"\n",
    "}\n",
    "\n",
    "# Plot ROC curve for each model\n",
    "for name in models_to_summarize:\n",
    "    if name in all_results:\n",
    "        res = all_results[name]\n",
    "        fpr, tpr, _ = roc_curve(y_test, res[\"y_proba\"])\n",
    "        auc_score = res[\"roc_auc\"]\n",
    "        plt.plot(fpr, tpr, color=colors[name], lw=2, \n",
    "                 label=f\"{name} (AUC = {auc_score:.4f})\")\n",
    "\n",
    "# Plot diagonal line (random classifier)\n",
    "plt.plot([0, 1], [0, 1], color=\"gray\", lw=2, linestyle=\"--\", label=\"Random (AUC = 0.5)\")\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate (1 - Specificity)\", fontsize=12)\n",
    "plt.ylabel(\"True Positive Rate (Sensitivity/Recall)\", fontsize=12)\n",
    "plt.title(\"ROC Curves - All Models Comparison\", fontsize=14)\n",
    "plt.legend(loc=\"lower right\", fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"roc_curves_all_models.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"ROC curves saved to 'roc_curves_all_models.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3e80a8-f132-4046-b7b8-dfac51a33162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 7C. PRECISION-RECALL CURVES (ALL MODELS)\n",
    "# ==========================================\n",
    "print(\"\\n>>> STEP 7C: Plotting Precision-Recall Curves for All Models...\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot PR curve for each model\n",
    "for name in models_to_summarize:\n",
    "    if name in all_results:\n",
    "        res = all_results[name]\n",
    "        precision, recall, _ = precision_recall_curve(y_test, res[\"y_proba\"])\n",
    "        pr_auc = res[\"pr_auc\"]\n",
    "        plt.plot(recall, precision, color=colors[name], lw=2,\n",
    "                 label=f\"{name} (PR AUC = {pr_auc:.4f})\")\n",
    "\n",
    "# Plot baseline (proportion of positive class)\n",
    "baseline = y_test.mean()\n",
    "plt.axhline(y=baseline, color=\"gray\", lw=2, linestyle=\"--\", \n",
    "            label=f\"Baseline (Prevalence = {baseline:.4f})\")\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"Recall (Sensitivity)\", fontsize=12)\n",
    "plt.ylabel(\"Precision\", fontsize=12)\n",
    "plt.title(\"Precision-Recall Curves - All Models Comparison\", fontsize=14)\n",
    "plt.legend(loc=\"upper right\", fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"pr_curves_all_models.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Precision-Recall curves saved to 'pr_curves_all_models.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864b12b8-9ad4-46d6-a9c9-4af69113cd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 7D. SHAP ANALYSIS (TREE-BASED MODELS)\n",
    "# ==========================================\n",
    "print(\"\\n>>> STEP 7D: SHAP Analysis for Tree-based Models...\")\n",
    "\n",
    "# Initialize SHAP\n",
    "shap.initjs()\n",
    "\n",
    "# Sample data for SHAP (to speed up computation)\n",
    "if len(X_test) > 1000:\n",
    "    shap_sample_idx = np.random.choice(len(X_test), size=1000, replace=False)\n",
    "    X_shap = X_test.iloc[shap_sample_idx]\n",
    "else:\n",
    "    X_shap = X_test\n",
    "\n",
    "print(f\"Using {len(X_shap)} samples for SHAP analysis\")\n",
    "\n",
    "# Models to analyze with SHAP (tree-based models only)\n",
    "shap_models = {\n",
    "    \"RF_Tuned\": trained_models[\"RF_Tuned\"],\n",
    "    \"XGBoost\": trained_models[\"XGBoost\"],\n",
    "    \"LightGBM\": trained_models[\"LightGBM\"]\n",
    "}\n",
    "\n",
    "# Store SHAP values for each model\n",
    "shap_values_dict = {}\n",
    "\n",
    "for name, model in shap_models.items():\n",
    "    print(f\"\\n>>> Computing SHAP values for {name}...\")\n",
    "    \n",
    "    # Create explainer\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_shap)\n",
    "    \n",
    "    # Handle different SHAP output formats\n",
    "    if isinstance(shap_values, list):\n",
    "        # For RF: shap_values is [class_0, class_1], we want class_1\n",
    "        shap_values_to_plot = shap_values[1]\n",
    "    else:\n",
    "        shap_values_to_plot = shap_values\n",
    "    \n",
    "    shap_values_dict[name] = shap_values_to_plot\n",
    "    \n",
    "    # Plot SHAP summary\n",
    "    print(f\"\\n--- SHAP Summary Plot: {name} ---\")\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    shap.summary_plot(shap_values_to_plot, X_shap, feature_names=feature_cols, show=False)\n",
    "    plt.title(f\"SHAP Summary Plot - {name}\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"shap_summary_{name}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(f\"Saved to 'shap_summary_{name}.png'\")\n",
    "\n",
    "print(\"\\n>>> SHAP Summary Plots complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b31d14-7a5c-431f-bc93-ae3f53f0231d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 7D-2. SHAP FEATURE IMPORTANCE (NUMERICAL)\n",
    "# ==========================================\n",
    "print(\"\\n>>> STEP 7D-2: SHAP Feature Importance (Numerical)...\")\n",
    "\n",
    "# Store feature importance for each model\n",
    "feature_importance_dict = {}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" SHAP GLOBAL FEATURE IMPORTANCE (Mean |SHAP Value|)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for name, shap_vals in shap_values_dict.items():\n",
    "    # Compute mean absolute SHAP values\n",
    "    mean_abs_shap = np.abs(shap_vals).mean(axis=0)\n",
    "    \n",
    "    # Ensure it's a 1D array\n",
    "    mean_abs_shap = np.ravel(mean_abs_shap)\n",
    "    \n",
    "    # Handle length mismatch\n",
    "    n_features = min(len(feature_cols), len(mean_abs_shap))\n",
    "    \n",
    "    # Create feature importance list\n",
    "    importance_list = [(feature_cols[i], float(mean_abs_shap[i])) for i in range(n_features)]\n",
    "    importance_list_sorted = sorted(importance_list, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    feature_importance_dict[name] = importance_list_sorted\n",
    "    \n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    print(f\"{'Rank':<6} {'Feature':<25} {'Mean |SHAP|':>12}\")\n",
    "    print(\"-\"*45)\n",
    "    for rank, (feat, val) in enumerate(importance_list_sorted, 1):\n",
    "        print(f\"{rank:<6} {feat:<25} {val:>12.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# ==========================================\n",
    "# 7D-3. COMBINED FEATURE IMPORTANCE BAR PLOT\n",
    "# ==========================================\n",
    "print(\"\\n>>> STEP 7D-3: Combined Feature Importance Bar Plot...\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for idx, (name, importance_list) in enumerate(feature_importance_dict.items()):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Get top 10 features\n",
    "    top_n = min(10, len(importance_list))\n",
    "    features = [x[0] for x in importance_list[:top_n]][::-1]\n",
    "    values = [x[1] for x in importance_list[:top_n]][::-1]\n",
    "    \n",
    "    ax.barh(range(top_n), values, color=colors[name])\n",
    "    ax.set_yticks(range(top_n))\n",
    "    ax.set_yticklabels(features)\n",
    "    ax.set_xlabel(\"Mean |SHAP Value|\")\n",
    "    ax.set_title(f\"{name}\")\n",
    "    ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.suptitle(\"Feature Importance Comparison (SHAP)\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"shap_feature_importance_comparison.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved to 'shap_feature_importance_comparison.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138be243-2b14-4aba-a6b9-184329dc6777",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# ==========================================\n",
    "# 7E. COMPREHENSIVE THRESHOLD TUNING\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\">>> STEP 7E: Threshold Optimization for All Candidate Models\")\n",
    "print(\"=\"*80)\n",
    "print(\"Rationale: Given the class imbalance and the comparable performance of top models,\")\n",
    "print(\"we optimize the decision threshold for all candidates to maximize the F1-score.\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Select models to tune (Top performers + Baseline)\n",
    "models_to_tune = [\"LightGBM\", \"XGBoost\", \"RF_Tuned\", \"LogisticRegression\"]\n",
    "tuning_results = []\n",
    "\n",
    "# Header for the output table\n",
    "header = f\"{'Model':<20} {'Default F1':<12} {'Optimized F1':<14} {'Best Threshold':<16} {'Improvement':<12}\"\n",
    "print(header)\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for name in models_to_tune:\n",
    "    if name in all_results:\n",
    "        # Get probability scores for the positive class\n",
    "        y_proba = all_results[name][\"y_proba\"]\n",
    "        y_true = y_test \n",
    "        \n",
    "        best_f1 = -1\n",
    "        best_thr = -1\n",
    "        best_prec = -1\n",
    "        best_rec = -1\n",
    "        \n",
    "        # Grid search for the best threshold (0.10 to 0.90)\n",
    "        thresholds = np.linspace(0.1, 0.9, 81)\n",
    "        \n",
    "        for thr in thresholds:\n",
    "            y_pred_thr = (y_proba >= thr).astype(int)\n",
    "            # Calculate F1 score (zero_division=0 handles cases with no positive predictions)\n",
    "            current_f1 = f1_score(y_true, y_pred_thr, zero_division=0)\n",
    "            \n",
    "            if current_f1 > best_f1:\n",
    "                best_f1 = current_f1\n",
    "                best_thr = thr\n",
    "                best_prec = precision_score(y_true, y_pred_thr, zero_division=0)\n",
    "                best_rec = recall_score(y_true, y_pred_thr, zero_division=0)\n",
    "        \n",
    "        # Calculate improvement over default threshold (0.5)\n",
    "        default_f1 = all_results[name][\"f1_score\"]\n",
    "        improvement = best_f1 - default_f1\n",
    "        \n",
    "        # Print row in the table\n",
    "        print(f\"{name:<20} {default_f1:<12.4f} {best_f1:<14.4f} {best_thr:<16.3f} {improvement:+.4f}\")\n",
    "        \n",
    "        # Store detailed results for plotting or further analysis\n",
    "        tuning_results.append({\n",
    "            \"Model\": name,\n",
    "            \"Default_F1\": default_f1,\n",
    "            \"Optimized_F1\": best_f1,\n",
    "            \"Best_Threshold\": best_thr,\n",
    "            \"Precision\": best_prec,\n",
    "            \"Recall\": best_rec\n",
    "        })\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(\"Observation: Threshold tuning significantly impacts models like Logistic Regression,\")\n",
    "print(\"demonstrating their potential competitiveness when properly calibrated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78dbc0e-cf9d-45bb-b86c-e0666434de36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 7E-5. EXECUTION TIME COMPARISON\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\">>> EXECUTION TIME COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import time\n",
    "\n",
    "execution_times = {}\n",
    "\n",
    "models_for_timing = {\n",
    "    \"RF_Tuned\": rf_tuned,\n",
    "    \"XGBoost\": xgb_model,\n",
    "    \"LightGBM\": lgb_model,\n",
    "    \"LogisticRegression\": lr_model,\n",
    "    \"KNN\": knn_pipeline,\n",
    "    \"NaiveBayes\": nb_model,\n",
    "}\n",
    "\n",
    "print(\"\\nMeasuring 5-fold CV execution time for each model...\\n\")\n",
    "\n",
    "for name, model in models_for_timing.items():\n",
    "    print(f\"  Timing {name}...\", end=\" \", flush=True)\n",
    "    start_time = time.time()\n",
    "    _ = cross_val_score(model, X_train, y_train, cv=5, scoring='f1', n_jobs=-1)\n",
    "    elapsed = time.time() - start_time\n",
    "    execution_times[name] = elapsed\n",
    "    print(f\"{elapsed:.2f} seconds\")\n",
    "\n",
    "# Plot\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EXECUTION TIME SUMMARY (5-fold CV)\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'Model':<25} {'Time (seconds)':>15}\")\n",
    "print(\"-\"*50)\n",
    "for name, t in sorted(execution_times.items(), key=lambda x: x[1]):\n",
    "    print(f\"{name:<25} {t:>15.2f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "models_sorted = sorted(execution_times.keys(), key=lambda x: execution_times[x])\n",
    "times_sorted = [execution_times[m] for m in models_sorted]\n",
    "plt.barh(models_sorted, times_sorted, color='steelblue')\n",
    "plt.xlabel('Execution Time (seconds)', fontsize=12)\n",
    "plt.title('Model Training Time Comparison (5-fold CV)', fontsize=14)\n",
    "for i, t in enumerate(times_sorted):\n",
    "    plt.text(t + 0.1, i, f'{t:.2f}s', va='center')\n",
    "plt.tight_layout()\n",
    "plt.savefig('execution_time_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: execution_time_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42bea1e-3e24-4788-8f65-ff6a996aa87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 7F. FINAL MODEL SUMMARY\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\">>> STEP 7F: FINAL MODEL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ==========================================\n",
    "# 7F-1. TEST SET RESULTS COMPARISON\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\" TEST SET RESULTS COMPARISON\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Create summary dataframe\n",
    "summary_data = []\n",
    "for name in models_to_summarize:\n",
    "    if name in all_results:\n",
    "        res = all_results[name]\n",
    "        summary_data.append({\n",
    "            \"Model\": name,\n",
    "            \"Accuracy\": res[\"accuracy\"],\n",
    "            \"Precision\": res[\"precision\"],\n",
    "            \"Recall\": res[\"recall\"],\n",
    "            \"F1-Score\": res[\"f1_score\"],\n",
    "            \"Specificity\": res[\"specificity\"],\n",
    "            \"ROC AUC\": res[\"roc_auc\"],\n",
    "            \"PR AUC\": res[\"pr_auc\"]\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df = summary_df.sort_values(\"F1-Score\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nRanked by F1-Score (Test Set):\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# ==========================================\n",
    "# 7F-2. 10-FOLD CV RESULTS COMPARISON\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\" 10-FOLD CROSS-VALIDATION RESULTS COMPARISON\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "cv_summary_data = []\n",
    "for name, res in cv_results.items():\n",
    "    cv_summary_data.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": f\"{res['accuracy_mean']:.4f}±{res['accuracy_std']:.4f}\",\n",
    "        \"Precision\": f\"{res['precision_mean']:.4f}±{res['precision_std']:.4f}\",\n",
    "        \"Recall\": f\"{res['recall_mean']:.4f}±{res['recall_std']:.4f}\",\n",
    "        \"F1-Score\": f\"{res['f1_mean']:.4f}±{res['f1_std']:.4f}\",\n",
    "        \"ROC AUC\": f\"{res['roc_auc_mean']:.4f}±{res['roc_auc_std']:.4f}\",\n",
    "        \"F1_mean\": res['f1_mean']  # for sorting\n",
    "    })\n",
    "\n",
    "cv_summary_df = pd.DataFrame(cv_summary_data)\n",
    "cv_summary_df = cv_summary_df.sort_values(\"F1_mean\", ascending=False).reset_index(drop=True)\n",
    "cv_summary_df = cv_summary_df.drop(columns=[\"F1_mean\"])\n",
    "\n",
    "print(\"\\nRanked by F1-Score (10-Fold CV):\")\n",
    "print(cv_summary_df.to_string(index=False))\n",
    "\n",
    "# ==========================================\n",
    "# 7F-3. BEST MODEL SUMMARY\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\" BEST MODEL SUMMARY\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Best model from 10-fold CV\n",
    "best_cv_model = max(cv_results, key=lambda x: cv_results[x][\"f1_mean\"])\n",
    "best_cv_f1 = cv_results[best_cv_model][\"f1_mean\"]\n",
    "\n",
    "# Best model from test set\n",
    "best_test_model = max(models_to_summarize, key=lambda x: all_results[x][\"f1_score\"] if x in all_results else 0)\n",
    "best_test_f1 = all_results[best_test_model][\"f1_score\"]\n",
    "\n",
    "print(f\"\\nBest Model (10-Fold CV):  {best_cv_model} (F1 = {best_cv_f1:.4f})\")\n",
    "print(f\"Best Model (Test Set):    {best_test_model} (F1 = {best_test_f1:.4f})\")\n",
    "print(f\"Optimal Threshold:        {best_thr:.3f} (F1 = {best_f1:.4f})\")\n",
    "\n",
    "# ==========================================\n",
    "# 7F-4. KEY FINDINGS\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\" KEY FINDINGS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "1. MODEL PERFORMANCE:\n",
    "   - At default threshold (0.5), all top models achieved similar F1 ≈ 0.50\n",
    "   - Logistic Regression had the highest default F1-score (0.5036 in 10-fold CV)\n",
    "   - After threshold optimization, LightGBM achieved the best F1-score (0.5177)\n",
    "   - Tree-based models (LightGBM, XGBoost, RF) and Logistic Regression performed comparably\n",
    "   - KNN and Naive Bayes performed poorly (F1 = 0.29 and 0.40, respectively)\n",
    "\n",
    "2. CLASS IMBALANCE:\n",
    "   - Positive class (diabetes2=1): 32.56%\n",
    "   - Negative class (diabetes2=0): 67.44%\n",
    "   - Imbalance ratio: 1:2.07\n",
    "   - All models used class_weight='balanced' or scale_pos_weight to address imbalance\n",
    "\n",
    "3. FEATURE IMPORTANCE (SHAP):\n",
    "   - heart_disease and age are the dominant predictors in XGBoost and LightGBM\n",
    "   - race and blood_pressure showed moderate importance\n",
    "   - blurred_vision and pregnancy contributed minimally due to low prevalence\n",
    "\n",
    "4. THRESHOLD TUNING:\n",
    "   - Default threshold (0.5) is suboptimal for this dataset\n",
    "   - Optimal threshold for LightGBM: 0.410\n",
    "   - F1 improvement from threshold tuning: 0.4950 -> 0.5177 (+4.6%)\n",
    "   - Lowering threshold increases recall (0.60 -> 0.81) at the cost of precision\n",
    "\"\"\")\n",
    "print(\"=\"*80)\n",
    "print(\">>> ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5483da-ef3b-44c4-8283-d89058fc1567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# PUBLICATION-READY SUMMARY TABLES\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\">>> PUBLICATION-READY SUMMARY TABLES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Table 1: The Result of Test Set\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"TABLE: Test Set Performance Metrics\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "models_to_summarize = [\"RF_Baseline\", \"RF_Tuned\", \"XGBoost\", \"LightGBM\",\n",
    "                       \"LogisticRegression\", \"KNN\", \"NaiveBayes\"]\n",
    "\n",
    "table_data = []\n",
    "for name in models_to_summarize:\n",
    "    if name in all_results:\n",
    "        r = all_results[name]\n",
    "        table_data.append({\n",
    "            'Model': name,\n",
    "            'Accuracy': f\"{r['accuracy']:.4f}\",\n",
    "            'Precision': f\"{r['precision']:.4f}\",\n",
    "            'Recall': f\"{r['recall']:.4f}\",\n",
    "            'F1-Score': f\"{r['f1_score']:.4f}\",\n",
    "            'ROC-AUC': f\"{r['roc_auc']:.4f}\",\n",
    "            'PR-AUC': f\"{r['pr_auc']:.4f}\"\n",
    "        })\n",
    "\n",
    "table_df = pd.DataFrame(table_data)\n",
    "print(table_df.to_string(index=False))\n",
    "\n",
    "# CSV\n",
    "table_df.to_csv('model_performance_summary.csv', index=False)\n",
    "print(\"\\nSaved: model_performance_summary.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
